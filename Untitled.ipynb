{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13789, 2)\n"
     ]
    }
   ],
   "source": [
    "import gzip, csv, json\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from random import sample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "seed = random.seed(42)\n",
    "\n",
    "\n",
    "high_sub_cooc = pd.read_csv('./high_subcooc.csv', header=None, names=['author', 'subcooc'])\n",
    "low_sub_cooc1 = pd.read_csv('./low_subcooc.csv', header=None, names=['author', 'subcooc'])\n",
    "\n",
    "hsc_a = high_sub_cooc['author'].tolist()\n",
    "lsc_a = low_sub_cooc1['author'].tolist()\n",
    "\n",
    "true_low = list(set(lsc_a).difference(set(hsc_a)))\n",
    "low_sub_cooc = low_sub_cooc1.loc[low_sub_cooc1['author'].isin(true_low)]\n",
    "cooc1 = [high_sub_cooc, low_sub_cooc]\n",
    "cooc = high_sub_cooc.append(low_sub_cooc)\n",
    "\n",
    "\n",
    "pval_avg = []\n",
    "chi2_avg = []\n",
    "fields = ['avg_score', \n",
    "          'num_contra_comm', 'num_gilded_comm', 'num_distinguished_comm', 'consp_comm', \n",
    "          'avg_len_comm',  \n",
    "          'avg_score_posts', 'avg_replies', \n",
    "          'num_gilded_posts', 'num_distinguished_posts',\n",
    "          'consp_posts', \n",
    "          'avg_postlen', 'subcooc', 'reciprocity']\n",
    "\n",
    "fields_wbonds = ['avg_score', \n",
    "          'num_contra_comm', 'num_gilded_comm', 'num_distinguished_comm', 'consp_comm', \n",
    "          'avg_len_comm',  \n",
    "          'avg_score_posts', 'avg_replies', \n",
    "          'num_gilded_posts', 'num_distinguished_posts',\n",
    "          'consp_posts', \n",
    "          'avg_postlen']\n",
    "\n",
    "norm_fields = ['avg_score', \n",
    "          'num_contra_comm', 'num_gilded_comm', 'num_distinguished_comm', 'consp_comm', \n",
    "          'avg_len_comm',  \n",
    "          'avg_score_posts', 'avg_replies', \n",
    "          'num_gilded_posts', 'num_distinguished_posts',\n",
    "          'consp_posts', \n",
    "          'avg_postlen', 'subcooc', 'reciprocity']\n",
    "\n",
    "\n",
    "\n",
    "coms_dmonth = ['num_archived_comm',\n",
    " 'num_subs',\n",
    " 'num_contra_comm',\n",
    " 'num_gilded_comm',\n",
    " 'num_distinguished_comm',\n",
    " 'num_comments']\n",
    "\n",
    "posts_dmonth=[\n",
    " 'num_archived_posts',\n",
    " 'num_subs_posts',\n",
    " 'num_gilded_posts',\n",
    " 'num_distinguished_posts',\n",
    " 'num_posts',\n",
    " 'num_stickied_posts',\n",
    " 'num_over18_posts',\n",
    "         ]\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "high_recip = pd.read_csv('./high_reciprocity.csv', header=None, names=['author', 'reciprocity'])\n",
    "low_recip1 = pd.read_csv('./low_reciprocity.csv', header=None, names=['author', 'reciprocity'])\n",
    "\n",
    "hrc_a = high_recip['author'].tolist()\n",
    "lrc_a = low_recip1['author'].tolist()\n",
    "\n",
    "true_lowr = list(set(lrc_a).difference(set(hrc_a)))\n",
    "low_recip = low_recip1.loc[low_recip1['author'].isin(true_lowr)]\n",
    "\n",
    "recp1 = [high_recip, low_recip]\n",
    "recp = pd.concat(recp1)\n",
    "print recp.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "highF = pd.read_csv('./high.csv', sep=',')\n",
    "highF['label'] = 1\n",
    "lowF1 = pd.read_csv('./low.csv', sep=',')\n",
    "lowF1['label']=0\n",
    "\n",
    "for p_tries in range(500):\n",
    "    newF = pd.DataFrame()\n",
    "    newF = newF.append(lowF1.sample(n=len(highF), random_state=seed))\n",
    "    newF = newF.append(highF.sample(n=len(highF), random_state=seed))\n",
    "    newF = newF.dropna(0)\n",
    "\n",
    "    withWeak = pd.merge(newF, cooc, how='left', on=['author'])\n",
    "\n",
    "    withStrong = pd.merge(newF, recp, how='left', on=['author'])\n",
    "    withBonds = pd.merge(withWeak, recp, how='left', on=['author'])\n",
    "\n",
    "    withBonds = withBonds.dropna(0)\n",
    "    #print withBonds.shape\n",
    "\n",
    "    #newF = newF.dropna()\n",
    "    vnewF = pd.DataFrame()\n",
    "    for field in norm_fields:\n",
    "        x = withBonds[[field]].values.astype(float)\n",
    "\n",
    "        # Create a minimum and maximum processor object\n",
    "        min_max_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "        # Create an object to transform the data to fit minmax processor\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "        #print type(x_scaled)\n",
    "        # Run the normalizer on the dataframe\n",
    "        #newF[field] = pd.DataFrame(x_scaled.T)\n",
    "        withBonds[field] = x_scaled\n",
    "\n",
    "\n",
    "\n",
    "    X = withBonds[fields]\n",
    "    #print X.head()\n",
    "    #Dependent variables\n",
    "    y = withBonds['label']\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, shuffle=True)\n",
    "\n",
    "    classifier_RF1 = LogisticRegression(random_state=seed)\n",
    "\n",
    "    classifier_RF1.fit(X_train, y_train)\n",
    "    rf_predict = classifier_RF1.predict(X_test)\n",
    "    X_train = X_train.loc[:, ~X_train.columns.isin(['reciprocity', 'subcooc'])]\n",
    "\n",
    "    X_test = X_test.loc[:, ~X_test.columns.isin(['reciprocity', 'subcooc'])]\n",
    "\n",
    "\n",
    "    classifier_RF2 = LogisticRegression(random_state=seed)\n",
    "\n",
    "    classifier_RF2.fit(X_train, y_train)\n",
    "    rf_predict_wbonds = classifier_RF2.predict(X_test)\n",
    "\n",
    "\n",
    "    from mlxtend.evaluate import mcnemar_table\n",
    "    tb = mcnemar_table(y_test, rf_predict, rf_predict_wbonds)\n",
    "    #print tb\n",
    "\n",
    "    #print rf_predict[300:400]\n",
    "    #print rf_predict_wbonds[300:400]\n",
    "\n",
    "    from mlxtend.evaluate import mcnemar\n",
    "    chi2, p = mcnemar(tb, corrected=True)\n",
    "    #print chi2\n",
    "    #print p\n",
    "    chi2_avg.append(chi2)\n",
    "    pval_avg.append(p)\n",
    "\n",
    "import numpy as np\n",
    "print np.mean(np.array(pval_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.297405137557\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
